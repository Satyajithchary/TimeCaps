{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile batchbot.py\nfrom keras.backend import *\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\n\n\n#own_batch_dot = batch_dot  # force standard implementation \n\n# import of batch_dot operation from TF 1.13\n# https://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/python/keras/backend.py\n\ndef own_batch_dot(x, y, axes=None):\n  \"\"\"Batchwise dot product.\n  `batch_dot` is used to compute dot product of `x` and `y` when\n  `x` and `y` are data in batch, i.e. in a shape of\n  `(batch_size, :)`.\n  `batch_dot` results in a tensor or variable with less dimensions\n  than the input. If the number of dimensions is reduced to 1,\n  we use `expand_dims` to make sure that ndim is at least 2.\n  Arguments:\n      x: Keras tensor or variable with `ndim >= 2`.\n      y: Keras tensor or variable with `ndim >= 2`.\n      axes: list of (or single) int with target dimensions.\n          The lengths of `axes[0]` and `axes[1]` should be the same.\n  Returns:\n      A tensor with shape equal to the concatenation of `x`'s shape\n      (less the dimension that was summed over) and `y`'s shape\n      (less the batch dimension and the dimension that was summed over).\n      If the final rank is 1, we reshape it to `(batch_size, 1)`.\n  Examples:\n      Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n      `batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal\n      of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n      elements.\n      Shape inference:\n      Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n      If `axes` is (1, 2), to find the output shape of resultant tensor,\n          loop through each dimension in `x`'s shape and `y`'s shape:\n      * `x.shape[0]` : 100 : append to output shape\n      * `x.shape[1]` : 20 : do not append to output shape,\n          dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n      * `y.shape[0]` : 100 : do not append to output shape,\n          always ignore first dimension of `y`\n      * `y.shape[1]` : 30 : append to output shape\n      * `y.shape[2]` : 20 : do not append to output shape,\n          dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n      `output_shape` = `(100, 30)`\n  ```python\n      >>> x_batch = K.ones(shape=(32, 20, 1))\n      >>> y_batch = K.ones(shape=(32, 30, 20))\n      >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n      >>> K.int_shape(xy_batch_dot)\n      (32, 1, 30)\n  ```\n  \"\"\"\n  if isinstance(axes, int):\n    axes = (axes, axes)\n  x_ndim = ndim(x)\n  y_ndim = ndim(y)\n  if axes is None:\n    # behaves like tf.batch_matmul as default\n    axes = [x_ndim - 1, y_ndim - 2]\n  if x_ndim > y_ndim:\n    diff = x_ndim - y_ndim\n    y = array_ops.reshape(y,\n                          array_ops.concat(\n                              [array_ops.shape(y), [1] * (diff)], axis=0))\n  elif y_ndim > x_ndim:\n    diff = y_ndim - x_ndim\n    x = array_ops.reshape(x,\n                          array_ops.concat(\n                              [array_ops.shape(x), [1] * (diff)], axis=0))\n  else:\n    diff = 0\n  if ndim(x) == 2 and ndim(y) == 2:\n    if axes[0] == axes[1]:\n      out = math_ops.reduce_sum(math_ops.multiply(x, y), axes[0])\n    else:\n      out = math_ops.reduce_sum(\n          math_ops.multiply(array_ops.transpose(x, [1, 0]), y), axes[1])\n  else:\n    adj_x = None if axes[0] == ndim(x) - 1 else True\n    adj_y = True if axes[1] == ndim(y) - 1 else None\n    out = math_ops.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n  if diff:\n    if x_ndim > y_ndim:\n      idx = x_ndim + y_ndim - 3\n    else:\n      idx = x_ndim - 1\n    out = array_ops.squeeze(out, list(range(idx, idx + diff)))\n  if ndim(out) == 1:\n    out = expand_dims(out, 1)\n  return out","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:08:23.359936Z","iopub.execute_input":"2024-10-07T15:08:23.360348Z","iopub.status.idle":"2024-10-07T15:08:23.368557Z","shell.execute_reply.started":"2024-10-07T15:08:23.360310Z","shell.execute_reply":"2024-10-07T15:08:23.367516Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Writing batchbot.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%run batchbot.py","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:08:36.745395Z","iopub.execute_input":"2024-10-07T15:08:36.746142Z","iopub.status.idle":"2024-10-07T15:08:36.753201Z","shell.execute_reply.started":"2024-10-07T15:08:36.746100Z","shell.execute_reply":"2024-10-07T15:08:36.752197Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/working/batchbot.py","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:10:47.456773Z","iopub.execute_input":"2024-10-07T15:10:47.457166Z","iopub.status.idle":"2024-10-07T15:10:53.539402Z","shell.execute_reply.started":"2024-10-07T15:10:47.457126Z","shell.execute_reply":"2024-10-07T15:10:53.538120Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# **Capslayers**","metadata":{}},{"cell_type":"code","source":"%%writefile capslayers.py\nfrom keras import backend as K\nimport tensorflow as tf\nimport numpy as np\nfrom keras import layers, initializers, regularizers, constraints\n#from keras.utils import conv_utils\nfrom keras.layers import InputSpec\n#from keras.utils.conv_utils import conv_output_length\n#from tensorflow.keras.utils import conv_utils\nfrom tensorflow.python.keras.utils import conv_utils\nfrom tensorflow.python.keras.utils.conv_utils import conv_output_length\n#from tensorflow.python.keras.utils import conv_output_length\nfrom batchbot import own_batch_dot\n\n\ncf = K.image_data_format() == '..'\nuseGPU = True\n\n\ndef squeeze(s):\n    sq = K.sum(K.square(s), axis=-1, keepdims=True)\n    return (sq / (1 + sq)) * (s / K.sqrt(sq + K.epsilon()))\n\n\nclass ConvertToCaps(layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(ConvertToCaps, self).__init__(**kwargs)\n        # self.input_spec = InputSpec(min_ndim=2)\n\n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n        output_shape.insert(1 if cf else len(output_shape), 1)\n        return tuple(output_shape)\n\n    def call(self, inputs):\n        return K.expand_dims(inputs, 1 if cf else -1)\n\n    def get_config(self):\n        config = {\n            'input_spec': 5\n        }\n        base_config = super(ConvertToCaps, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass FlattenCaps(layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(FlattenCaps, self).__init__(**kwargs)\n        self.input_spec = InputSpec(min_ndim=4)\n\n    def compute_output_shape(self, input_shape):\n        if not all(input_shape[1:]):\n            raise ValueError('The shape of the input to \"FlattenCaps\" '\n                             'is not fully defined '\n                             '(got ' + str(input_shape[1:]) + '. '\n                             'Make sure to pass a complete \"input_shape\" '\n                             'or \"batch_input_shape\" argument to the first '\n                             'layer in your model.')\n        return (input_shape[0], np.prod(input_shape[1:-1]), input_shape[-1])\n\n    def call(self, inputs):\n        shape = K.int_shape(inputs)\n        return K.reshape(inputs, (-1, np.prod(shape[1:-1]), shape[-1]))\n\n\nclass CapsToScalars(layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(CapsToScalars, self).__init__(**kwargs)\n        self.input_spec = InputSpec(min_ndim=3)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1])\n\n    def call(self, inputs):\n        return K.sqrt(K.sum(K.square(inputs + K.epsilon()), axis=-1))\n\n\nclass Conv2DCaps(layers.Layer):\n\n    def __init__(self, ch_j, n_j,\n                 kernel_size=(3, 3),\n                 strides=(1, 1),\n                 r_num=1,\n                 b_alphas=[8, 8, 8],\n                 padding='same',\n                 data_format='channels_last',\n                 dilation_rate=(1, 1),\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 **kwargs):\n        super(Conv2DCaps, self).__init__(**kwargs)\n        rank = 2\n        self.ch_j = ch_j  # Number of capsules in layer J\n        self.n_j = n_j  # Number of neurons in a capsule in J\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n        self.r_num = r_num\n        self.b_alphas = b_alphas\n        self.padding = conv_utils.normalize_padding(padding)\n        #self.data_format = conv_utils.normalize_data_format(data_format)\n        self.data_format = K.normalize_data_format(data_format)\n        self.dilation_rate = (1, 1)\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.input_spec = InputSpec(ndim=rank + 3)\n\n    def build(self, input_shape):\n\n        self.h_i, self.w_i, self.ch_i, self.n_i = input_shape[1:5]\n\n        self.h_j, self.w_j = [conv_utils.conv_output_length(input_shape[i + 1],\n                                                            self.kernel_size[i],\n                                                            padding=self.padding,\n                                                            stride=self.strides[i],\n                                                            dilation=self.dilation_rate[i]) for i in (0, 1)]\n\n        self.ah_j, self.aw_j = [conv_utils.conv_output_length(input_shape[i + 1],\n                                                              self.kernel_size[i],\n                                                              padding=self.padding,\n                                                              stride=1,\n                                                              dilation=self.dilation_rate[i]) for i in (0, 1)]\n\n        self.w_shape = self.kernel_size + (self.ch_i, self.n_i,\n                                           self.ch_j, self.n_j)\n\n        self.w = self.add_weight(shape=self.w_shape,\n                                 initializer=self.kernel_initializer,\n                                 name='kernel',\n                                 regularizer=self.kernel_regularizer,\n                                 constraint=self.kernel_constraint)\n\n        self.built = True\n\n    def call(self, inputs):\n        if self.r_num == 1:\n            # if there is no routing (and this is so when r_num is 1 and all c are equal)\n            # then this is a common convolution\n            outputs = K.conv2d(K.reshape(inputs, (-1, self.h_i, self.w_i,\n                                                  self.ch_i * self.n_i)),\n                               K.reshape(self.w, self.kernel_size +\n                                         (self.ch_i * self.n_i, self.ch_j * self.n_j)),\n                               data_format='channels_last',\n                               strides=self.strides,\n                               padding=self.padding,\n                               dilation_rate=self.dilation_rate)\n\n            outputs = squeeze(K.reshape(outputs, ((-1, self.h_j, self.w_j,\n                                                   self.ch_j, self.n_j))))\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.h_j, self.w_j, self.ch_j, self.n_j)\n\n    def get_config(self):\n        config = {\n            'ch_j': self.ch_j,\n            'n_j': self.n_j,\n            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n            'b_alphas': self.b_alphas,\n            'padding': self.padding,\n            'data_format': self.data_format,\n            'dilation_rate': self.dilation_rate,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint)\n        }\n        base_config = super(Conv2DCaps, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass Mask(layers.Layer):\n\n    def call(self, inputs, **kwargs):\n        if isinstance(inputs, list):  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n            assert len(inputs) == 2\n            inputs, mask = inputs\n        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n            # compute lengths of capsules\n            x = K.sqrt(K.sum(K.square(inputs), -1))\n            # generate the mask which is a one-hot code.\n            # mask.shape=[None, n_classes]=[None, num_capsule]\n            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n\n        # inputs.shape=[None, num_capsule, dim_capsule]\n        # mask.shape=[None, num_capsule]\n        # masked.shape=[None, num_capsule * dim_capsule]\n        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n        return masked\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape[0], tuple):  # true label provided\n            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n        else:  # no true label provided\n            return tuple([None, input_shape[1] * input_shape[2]])\n\n\nclass Mask_CID(layers.Layer):\n\n    def call(self, inputs, **kwargs):\n        if isinstance(inputs, list):  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n            assert len(inputs) == 2\n            inputs, a = inputs\n            mask = K.argmax(a, 1)\n        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n            # compute lengths of capsules\n            x = K.sqrt(K.sum(K.square(inputs), -1))\n            # generate the mask which is a one-hot code.\n            # mask.shape=[None, n_classes]=[None, num_capsule]\n            mask = K.argmax(x, 1)\n\n        increasing = tf.range(start=0, limit=tf.shape(inputs)[0], delta=1)\n        m = tf.stack([increasing, tf.cast(mask, tf.int32)], axis=1)\n        # inputs.shape=[None, num_capsule, dim_capsule]\n        # mask.shape=[None, num_capsule]\n        # masked.shape=[None, num_capsule * dim_capsule]\n        # x1 = tf.transpose(inputs, (0))\n        masked = tf.gather_nd(inputs, m)\n\n        return masked\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape[0], tuple):  # true label provided\n            return tuple([None, input_shape[0][2]])\n        else:  # no true label provided\n            return tuple([None, input_shape[2]])\n\n\nclass ConvCapsuleLayer3D(layers.Layer):\n\n    def __init__(self, kernel_size, num_capsule, num_atoms, strides=1, padding='valid', routings=3,\n                 kernel_initializer='he_normal', **kwargs):\n        super(ConvCapsuleLayer3D, self).__init__(**kwargs)\n        self.kernel_size = kernel_size\n        self.num_capsule = num_capsule\n        self.num_atoms = num_atoms\n        self.strides = strides\n        self.padding = padding\n        self.routings = routings\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 5, \"The input Tensor should have shape=[None, input_height, input_width,\" \\\n                                      \" input_num_capsule, input_num_atoms]\"\n        self.input_height = input_shape[1]\n        self.input_width = input_shape[2]\n        self.input_num_capsule = input_shape[3]\n        self.input_num_atoms = input_shape[4]\n\n        # Transform matrix\n        self.W = self.add_weight(shape=[self.input_num_atoms, self.kernel_size, self.kernel_size, 1, self.num_capsule * self.num_atoms],\n                                 initializer=self.kernel_initializer,\n                                 name='W')\n\n        self.b = self.add_weight(shape=[self.num_capsule, self.num_atoms, 1, 1],\n                                 initializer=initializers.constant(0.1),\n                                 name='b')\n\n        self.built = True\n\n    def call(self, input_tensor, training=None):\n\n        input_transposed = tf.transpose(input_tensor, [0, 3, 4, 1, 2])\n        input_shape = K.shape(input_transposed)\n        input_tensor_reshaped = K.reshape(input_tensor, [input_shape[0], 1, self.input_num_capsule * self.input_num_atoms, self.input_height, self.input_width])\n\n        input_tensor_reshaped.set_shape((None, 1, self.input_num_capsule * self.input_num_atoms, self.input_height, self.input_width))\n\n        # conv = Conv3D(input_tensor_reshaped, self.W, (self.strides, self.strides),\n        #                 padding=self.padding, data_format='channels_first')\n\n        conv = K.conv3d(input_tensor_reshaped, self.W, strides=(self.input_num_atoms, self.strides, self.strides), padding=self.padding, data_format='channels_first')\n\n        votes_shape = K.shape(conv)\n        _, _, _, conv_height, conv_width = conv.get_shape()\n        conv = tf.transpose(conv, [0, 2, 1, 3, 4])\n        votes = K.reshape(conv, [input_shape[0], self.input_num_capsule, self.num_capsule, self.num_atoms, votes_shape[3], votes_shape[4]])\n        votes.set_shape((None, self.input_num_capsule, self.num_capsule, self.num_atoms, conv_height.value, conv_width.value))\n\n        logit_shape = K.stack([input_shape[0], self.input_num_capsule, self.num_capsule, votes_shape[3], votes_shape[4]])\n        biases_replicated = K.tile(self.b, [1, 1, conv_height.value, conv_width.value])\n\n        activations = update_routing(\n            votes=votes,\n            biases=biases_replicated,\n            logit_shape=logit_shape,\n            num_dims=6,\n            input_dim=self.input_num_capsule,\n            output_dim=self.num_capsule,\n            num_routing=self.routings)\n\n        a2 = tf.transpose(activations, [0, 3, 4, 1, 2])\n        return a2\n\n    def compute_output_shape(self, input_shape):\n        space = input_shape[1:-2]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_output_length(space[i], self.kernel_size, padding=self.padding, stride=self.strides, dilation=1)\n            new_space.append(new_dim)\n\n        return (input_shape[0],) + tuple(new_space) + (self.num_capsule, self.num_atoms)\n\n    def get_config(self):\n        config = {\n            'kernel_size': self.kernel_size,\n            'num_capsule': self.num_capsule,\n            'num_atoms': self.num_atoms,\n            'strides': self.strides,\n            'padding': self.padding,\n            'routings': self.routings,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer)\n        }\n        base_config = super(ConvCapsuleLayer3D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\ndef update_routing(votes, biases, logit_shape, num_dims, input_dim, output_dim,\n                   num_routing):\n    if num_dims == 6:\n        votes_t_shape = [3, 0, 1, 2, 4, 5]\n        r_t_shape = [1, 2, 3, 0, 4, 5]\n    elif num_dims == 4:\n        votes_t_shape = [3, 0, 1, 2]\n        r_t_shape = [1, 2, 3, 0]\n    else:\n        raise NotImplementedError('Not implemented')\n\n    votes_trans = tf.transpose(votes, votes_t_shape)\n    _, _, _, height, width, caps = votes_trans.get_shape()\n\n    def _body(i, logits, activations):\n        \"\"\"Routing while loop.\"\"\"\n        # route: [batch, input_dim, output_dim, ...]\n        a,b,c,d,e = logits.get_shape()\n        a = logit_shape[0]\n        b = logit_shape[1]\n        c = logit_shape[2]\n        d = logit_shape[3]\n        e = logit_shape[4]\n        print(logit_shape)\n        logit_temp = tf.reshape(logits, [a,b,-1])\n        route_temp = tf.nn.softmax(logit_temp, dim=-1)\n        route = tf.reshape(route_temp, [a, b, c, d, e])\n        preactivate_unrolled = route * votes_trans\n        preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)\n        preactivate = tf.reduce_sum(preact_trans, axis=1) + biases\n        # activation = _squash(preactivate)\n        activation = squash(preactivate, axis=[-1, -2, -3])\n        activations = activations.write(i, activation)\n\n        act_3d = K.expand_dims(activation, 1)\n        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n        tile_shape[1] = input_dim\n        act_replicated = tf.tile(act_3d, tile_shape)\n        distances = tf.reduce_sum(votes * act_replicated, axis=3)\n        logits += distances\n        return (i + 1, logits, activations)\n\n    activations = tf.TensorArray(\n        dtype=tf.float32, size=num_routing, clear_after_read=False)\n    logits = tf.fill(logit_shape, 0.0)\n\n    i = tf.constant(0, dtype=tf.int32)\n    _, logits, activations = tf.while_loop(\n        lambda i, logits, activations: i < num_routing,\n        _body,\n        loop_vars=[i, logits, activations],\n        swap_memory=True)\n    a = K.cast(activations.read(num_routing - 1), dtype='float32')\n    return K.cast(activations.read(num_routing - 1), dtype='float32')\n\n\nclass DenseCaps(layers.Layer):\n\n    def __init__(self, ch_j, n_j,\n                 r_num=1,\n                 b_alphas=[8, 8, 8],\n                 kernel_initializer='glorot_uniform',\n                 kernel_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(DenseCaps, self).__init__(**kwargs)\n        self.ch_j = ch_j  # number of capsules in layer J\n        self.n_j = n_j  # number of neurons in a capsule in J\n        self.r_num = r_num\n        self.b_alphas = b_alphas\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.input_spec = InputSpec(min_ndim=3)\n        self.supports_masking = True\n\n    def build(self, input_shape):\n        self.ch_i, self.n_i = input_shape[1:]\n\n        self.w_shape = (self.ch_i, self.n_i, self.ch_j, self.n_j)\n\n        self.w = self.add_weight(shape=self.w_shape,\n                                 initializer=self.kernel_initializer,\n                                 name='kernel',\n                                 regularizer=self.kernel_regularizer,\n                                 constraint=self.kernel_constraint)\n\n        self.built = True\n\n    def call(self, inputs):\n        if self.r_num == 1:\n            outputs = K.dot(K.reshape(inputs, (-1, self.ch_i * self.n_i)),\n                            K.reshape(self.w, (self.ch_i * self.n_i,\n                                               self.ch_j * self.n_j)))\n            outputs = squeeze(K.reshape(outputs, (-1, self.ch_j, self.n_j)))\n        else:\n            wr = K.reshape(self.w, (self.ch_i, self.n_i, self.ch_j * self.n_j))\n\n            u = tf.transpose(tf.matmul(tf.transpose(inputs, [1, 0, 2]), wr), [1, 0, 2])\n\n            u = K.reshape(u, (-1, self.ch_i, self.ch_j, self.n_j))\n\n            def rt(ub):\n                ub = K.reshape(ub, (-1, self.ch_i, self.ch_j, self.n_j))\n                ub_wo_g = K.stop_gradient(ub)\n                b = 0.0\n                for r in range(self.r_num):\n                    if r > 0:\n                        c = K.expand_dims(K.softmax(b * self.b_alphas[r])) * self.ch_j  # distribution of weighs of capsules in I across capsules in J\n                        c = K.stop_gradient(c)\n                    else:\n                        c = 1.0\n\n                    if r == self.r_num - 1:\n                        cub = c * ub\n                    else:\n                        cub = c * ub_wo_g\n                    s = K.sum(cub, axis=-3)  # vectors of capsules in J\n                    v = squeeze(s)  # squeezed vectors of capsules in J\n                    if r == self.r_num - 1:\n                        break\n\n                    v = K.stop_gradient(v)\n\n                    a = tf.einsum('bjk,bijk->bij', v, ub)  # a = v dot u\n                    # a = K.matmul(K.reshape(v, (-1, 1, J, 1, n_j)),\n                    #             K.reshape(u, (-1, I, J, n_j, 1))).reshape((-1, I, J))\n\n                    b = b + a  # increase those b[i,j] where v[j] dot b[i,j] is larger\n                return v\n\n            u = K.reshape(u, (-1, self.ch_i * self.ch_j * self.n_j))\n\n            global useGPU\n\n            if useGPU:\n                outputs = rt(u)\n            else:\n                outputs = tf.map_fn(rt, u,\n                                    parallel_iterations=100, back_prop=True,\n                                    infer_shape=False)\n\n            outputs = K.reshape(outputs, (-1, self.ch_j, self.n_j))\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.ch_j, self.n_j)\n\n    def get_config(self):\n        config = {\n            'ch_j': self.ch_j,\n            'n_j': self.n_j,\n            'r_num': self.r_num,\n            'b_alphas': self.b_alphas,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n        }\n        base_config = super(DenseCaps, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclass CapsuleLayer(layers.Layer):\n\n    def __init__(self, num_capsule, dim_capsule, channels, routings=3,\n                 kernel_initializer='glorot_uniform',\n                 **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.channels = channels\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n        self.input_num_capsule = input_shape[1]\n        self.input_dim_capsule = input_shape[2]\n\n        if(self.channels != 0):\n            assert int(self.input_num_capsule / self.channels) / (self.input_num_capsule / self.channels) == 1, \"error\"\n            self.W = self.add_weight(shape=[self.num_capsule, self.channels,\n                                            self.dim_capsule, self.input_dim_capsule],\n                                     initializer=self.kernel_initializer,\n                                     name='W')\n\n            self.B = self.add_weight(shape=[self.num_capsule, self.dim_capsule],\n                                     initializer=self.kernel_initializer,\n                                     name='B')\n        else:\n            self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n                                            self.dim_capsule, self.input_dim_capsule],\n                                     initializer=self.kernel_initializer,\n                                     name='W')\n            self.B = self.add_weight(shape=[self.num_capsule, self.dim_capsule],\n                                     initializer=self.kernel_initializer,\n                                     name='B')\n\n        self.built = True\n\n    def call(self, inputs, training=None):\n        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n        inputs_expand = K.expand_dims(inputs, 1)\n\n        # Replicate num_capsule dimension to prepare being multiplied by W\n        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n\n        if(self.channels != 0):\n            W2 = K.repeat_elements(self.W, int(self.input_num_capsule / self.channels), 1)\n        else:\n            W2 = self.W\n        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n        # Regard the first two dimensions as `batch` dimension,\n        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n        inputs_hat = K.map_fn(lambda x: own_batch_dot(x, W2, [2, 3]), elems=inputs_tiled)\n\n        # Begin: Routing algorithm ---------------------------------------------------------------------#\n        # The prior for coupling coefficient, initialized as zeros.\n        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n\n        assert self.routings > 0, 'The routings should be > 0.'\n        for i in range(self.routings):\n            # c.shape=[batch_size, num_capsule, input_num_capsule]\n            c = tf.nn.softmax(b, dim=1)\n\n            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n            # The first two dimensions as `batch` dimension,\n            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n            # outputs.shape=[None, num_capsule, dim_capsule]\n            outputs = squash(own_batch_dot(c, inputs_hat, [2, 2]) + self.B)  # [None, 10, 16]\n\n            if i < self.routings - 1:\n                # outputs.shape =  [None, num_capsule, dim_capsule]\n                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n                # The first two dimensions as `batch` dimension,\n                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n                # b.shape=[batch_size, num_capsule, input_num_capsule]\n                b += own_batch_dot(outputs, inputs_hat, [2, 3])\n        # End: Routing algorithm -----------------------------------------------------------------------#\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.num_capsule, self.dim_capsule])\n\n\ndef _squash(input_tensor):\n    norm = tf.norm(input_tensor, axis=-1, keep_dims=True)\n    norm_squared = norm * norm\n    return (input_tensor / norm) * (norm_squared / (1 + norm_squared))\n\n\ndef squash(vectors, axis=-1):\n    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm)\n    return scale * vectors","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:11:11.330893Z","iopub.execute_input":"2024-10-07T15:11:11.331333Z","iopub.status.idle":"2024-10-07T15:11:11.357799Z","shell.execute_reply.started":"2024-10-07T15:11:11.331292Z","shell.execute_reply":"2024-10-07T15:11:11.356681Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Overwriting capslayers.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%run capslayers.py","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:11:12.863862Z","iopub.execute_input":"2024-10-07T15:11:12.864715Z","iopub.status.idle":"2024-10-07T15:11:12.876125Z","shell.execute_reply.started":"2024-10-07T15:11:12.864676Z","shell.execute_reply":"2024-10-07T15:11:12.875273Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Francescobovo/Snapshot_Ensemble_AutoMachineLearning","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:15:30.760415Z","iopub.execute_input":"2024-10-07T15:15:30.760848Z","iopub.status.idle":"2024-10-07T15:15:32.436760Z","shell.execute_reply.started":"2024-10-07T15:15:30.760806Z","shell.execute_reply":"2024-10-07T15:15:32.435572Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Cloning into 'Snapshot_Ensemble_AutoMachineLearning'...\nremote: Enumerating objects: 38, done.\u001b[K\nremote: Counting objects: 100% (38/38), done.\u001b[K\nremote: Compressing objects: 100% (37/37), done.\u001b[K\nremote: Total 38 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (38/38), 58.38 KiB | 1.17 MiB/s, done.\nResolving deltas: 100% (10/10), done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **snapshot_callback**","metadata":{}},{"cell_type":"code","source":"%%writefile snapshot_callback.py\nimport numpy as np\nimport os\n\nimport keras.callbacks as callbacks\nfrom keras.callbacks import Callback\n\nclass SnapshotModelCheckpoint(Callback):\n    \"\"\"Callback that saves the snapshot weights of the model.\n\n    Saves the model weights on certain epochs (which can be considered the\n    snapshot of the model at that epoch).\n\n    Should be used with the cosine annealing learning rate schedule to save\n    the weight just before learning rate is sharply increased.\n\n    # Arguments:\n        nb_epochs: total number of epochs that the model will be trained for.\n        nb_snapshots: number of times the weights of the model will be saved.\n        fn_prefix: prefix for the filename of the weights.\n    \"\"\"\n\n    def __init__(self, nb_epochs, nb_snapshots, fn_prefix='Model'):\n        super(SnapshotModelCheckpoint, self).__init__()\n\n        self.check = nb_epochs // nb_snapshots\n        self.fn_prefix = fn_prefix\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch != 0 and (epoch + 1) % self.check == 0:\n            filepath = self.fn_prefix + \"-%d.h5\" % ((epoch + 1) // self.check)\n            self.model.save_weights(filepath, overwrite=True)\n            #print(\"Saved snapshot at weights/%s_%d.h5\" % (self.fn_prefix, epoch))\n\n\nclass SnapshotCallbackBuilder:\n    \"\"\"Callback builder for snapshot ensemble training of a model.\n\n    Creates a list of callbacks, which are provided when training a model\n    so as to save the model weights at certain epochs, and then sharply\n    increase the learning rate.\n    \"\"\"\n\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n        \"\"\"\n        Initialize a snapshot callback builder.\n\n        # Arguments:\n            nb_epochs: total number of epochs that the model will be trained for.\n            nb_snapshots: number of times the weights of the model will be saved.\n            init_lr: initial learning rate\n        \"\"\"\n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n\n    def get_callbacks(self, model_prefix='Model'):\n        \"\"\"\n        Creates a list of callbacks that can be used during training to create a\n        snapshot ensemble of the model.\n\n        Args:\n            model_prefix: prefix for the filename of the weights.\n\n        Returns: list of 3 callbacks [ModelCheckpoint, LearningRateScheduler,\n                 SnapshotModelCheckpoint] which can be provided to the 'fit' function\n        \"\"\"\n        if not os.path.exists('weights/'):\n            os.makedirs('weights/')\n\n        callback_list = [callbacks.ModelCheckpoint(\"weights/%s-Best.h5\" % model_prefix, monitor=\"val_acc\",\n                                                    save_best_only=True, save_weights_only=True),\n                         callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule),\n                         SnapshotModelCheckpoint(self.T, self.M, fn_prefix='weights/%s' % model_prefix)]\n\n        return callback_list\n\n    def _cosine_anneal_schedule(self, t):\n        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n        cos_inner /= self.T // self.M\n        cos_out = np.cos(cos_inner) + 1\n        return float(self.alpha_zero / 2 * cos_out)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:32:52.507669Z","iopub.execute_input":"2024-10-07T15:32:52.508666Z","iopub.status.idle":"2024-10-07T15:32:52.516777Z","shell.execute_reply.started":"2024-10-07T15:32:52.508623Z","shell.execute_reply":"2024-10-07T15:32:52.515685Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Writing snapshot_callback.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%run snapshot_callback.py","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:33:02.398829Z","iopub.execute_input":"2024-10-07T15:33:02.399749Z","iopub.status.idle":"2024-10-07T15:33:02.406825Z","shell.execute_reply.started":"2024-10-07T15:33:02.399707Z","shell.execute_reply":"2024-10-07T15:33:02.405689Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import torch\n!pip install ema-pytorch\nfrom ema_pytorch import EMA","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:42:59.963578Z","iopub.execute_input":"2024-10-07T15:42:59.964478Z","iopub.status.idle":"2024-10-07T15:43:11.766559Z","shell.execute_reply.started":"2024-10-07T15:42:59.964438Z","shell.execute_reply":"2024-10-07T15:43:11.765522Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting ema-pytorch\n  Downloading ema_pytorch-0.7.0-py3-none-any.whl.metadata (691 bytes)\nRequirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.10/site-packages (from ema-pytorch) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->ema-pytorch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->ema-pytorch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->ema-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->ema-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->ema-pytorch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->ema-pytorch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0->ema-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0->ema-pytorch) (1.3.0)\nDownloading ema_pytorch-0.7.0-py3-none-any.whl (9.4 kB)\nInstalling collected packages: ema-pytorch\nSuccessfully installed ema-pytorch-0.7.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Installing Dependencies**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nKeras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\nThe current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\nAdopting to other backends should be easy, but I have not tested this. \n\nUsage:\n       python capsulenet.py\n       python capsulenet.py --epochs 50\n       python capsulenet.py --epochs 50 --routings 3\n       ... ...\n       \nResult:\n    Validation accuracy > 99.5% after 20 epochs. Converge to 99.66% after 50 epochs.\n    About 110 seconds per epoch on a single GTX1070 GPU card\n    \nAuthor: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n\"\"\"\n\"\"\"\nDemo of network with 5x5 convolutional layer, two 3x3 caps layers with\ncapsule-wise convolution and no routing and a capslayer with routing\nCreated on Sat Nov 24 16:35:22 2017\n@author: - Ruslan Grimov\n\"\"\"\nfrom collections.abc import Iterable\n#from keras import backend as K\nfrom keras import layers, models, optimizers\nfrom keras.datasets import mnist, cifar10\nfrom keras.models import Model, Sequential, load_model\nfrom keras.layers import Input, Conv2D, Activation, Dense, Dropout, Lambda, Reshape, Concatenate\n#from keras.layers import BatchNormalization, MaxPooling2D, Flatten, Conv1D, Deconvolution2D, Conv2DTranspose\nfrom keras.layers import BatchNormalization, MaxPooling2D, Flatten, Conv1D, Conv2DTranspose\n\nfrom capslayers import ConvertToCaps, Conv2DCaps, FlattenCaps\nfrom capslayers import DenseCaps, CapsToScalars\nfrom keras.utils import to_categorical\nfrom keras.callbacks import Callback, ModelCheckpoint, TensorBoard\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras import losses\nimport numpy as np\nimport tensorflow as tf\nimport os\nfrom snapshot_callback import SnapshotCallbackBuilder\nimport capslayers\n# import rescaps\nfrom keras.utils import plot_model\nfrom keras.layers import Dense, Reshape\nfrom keras.layers import Activation, Flatten\nfrom keras.layers import BatchNormalization\nfrom keras.layers import UpSampling2D, Conv2D, MaxPooling2D, Conv3D\n# import memory_saving_gradients\nfrom keras import initializers\n#from keras.utils.conv_utils import conv_output_length, deconv_length\nfrom tensorflow.python.keras.utils import conv_utils\nfrom tensorflow.python.keras.utils.conv_utils import conv_output_length\n#from tensorflow.python.keras.utils.conv_utils import deconv_length\nfrom keras.models import Model, Sequential, load_model\nimport ema_pytorch as ema\nimport os\nimport sys\n# from rescaps_v3D import *\n#from keras.utils import multi_gpu_model\nimport numpy as np\nfrom keras import layers, models,activations\nimport matplotlib.pyplot as plt\n#from keras import combine_images_1d\nfrom PIL import Image\n#from capslayers import CapsuleLayer, PrimaryCap, Length, Mask\nfrom capslayers import CapsuleLayer, Mask\nfrom sklearn.model_selection import train_test_split\nfrom capslayers import *\n# K.set_image_data_format('channels_last')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T16:09:10.575642Z","iopub.execute_input":"2024-10-07T16:09:10.576334Z","iopub.status.idle":"2024-10-07T16:09:11.462799Z","shell.execute_reply.started":"2024-10-07T16:09:10.576297Z","shell.execute_reply":"2024-10-07T16:09:11.461761Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"# **Mask Class**","metadata":{}},{"cell_type":"code","source":"def margin_loss(y_true, y_pred):\n    # L= y_true * K.clip(0.9 - y_pred, 0, 1) ** 2 + 0.5 * (1 - y_true) * K.clip(y_pred - 0.1, 0, 1) ** 2\n    # L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + 0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1)) +  K.square(K.maximum(0.,y_pred))\n    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + 0.1 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n    return K.mean(K.sum(L, 1))\n\n\nclass Mask(layers.Layer):\n    \"\"\"\n    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional\n    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n    masked Tensor.\n    For example:\n        ```\n        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n        out = Mask()(x)  # out.shape=[8, 6]\n        # or\n        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n        ```\n    \"\"\"\n\n    def call(self, inputs, **kwargs):\n        if isinstance(inputs, list):  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n            assert len(inputs) == 2\n            inputs, mask = inputs\n        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n            # compute lengths of capsules\n            x = K.sqrt(K.sum(K.square(inputs), -1))\n            # generate the mask which is a one-hot code.\n            # mask.shape=[None, n_classes]=[None, num_capsule]\n            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n\n        # inputs.shape=[None, num_capsule, dim_capsule]\n        # mask.shape=[None, num_capsule]\n        # masked.shape=[None, num_capsule * dim_capsule]\n        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n        return masked\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape[0], tuple):  # true label provided\n            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n        else:  # no true label provided\n            return tuple([None, input_shape[1] * input_shape[2]])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T16:10:15.161822Z","iopub.execute_input":"2024-10-07T16:10:15.162920Z","iopub.status.idle":"2024-10-07T16:10:15.174076Z","shell.execute_reply.started":"2024-10-07T16:10:15.162878Z","shell.execute_reply":"2024-10-07T16:10:15.173051Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"# **ConvCapsuleLayer3 Class**","metadata":{}},{"cell_type":"code","source":"class ConvCapsuleLayer3(layers.Layer):\n\n    def __init__(self, kernel_size, num_capsule, num_atoms, strides=1, padding='valid', routings=3,\n                 kernel_initializer='he_normal', **kwargs):\n        super(ConvCapsuleLayer3, self).__init__(**kwargs)\n        self.kernel_size = kernel_size\n        self.num_capsule = num_capsule\n        self.num_atoms = num_atoms\n        self.strides = strides\n        self.padding = padding\n        self.routings = routings\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 5, \"The input Tensor should have shape=[None, input_height, input_width,\" \\\n                                      \" input_num_capsule, input_num_atoms]\"\n        self.input_height = input_shape[1]\n        self.input_width = input_shape[2]\n        self.input_num_capsule = input_shape[3]\n        self.input_num_atoms = input_shape[4]\n\n        # Transform matrix\n        self.W = self.add_weight(shape=[self.input_num_atoms, self.kernel_size, 1, 1, self.num_capsule * self.num_atoms],\n                                 initializer=self.kernel_initializer,\n                                 name='W')\n\n        self.b = self.add_weight(shape=[self.num_capsule, self.num_atoms, 1, 1],\n                                 initializer=initializers.constant(0.1),\n                                 name='b')\n\n        self.built = True\n\n    def call(self, input_tensor, training=None):\n\n        input_transposed = tf.transpose(input_tensor, [0, 3, 4, 1, 2])\n        input_shape = K.shape(input_transposed)\n        print(\"###########################################################\", input_transposed.get_shape)\n        input_tensor_reshaped = K.reshape(input_tensor, [input_shape[0], 1, self.input_num_capsule * self.input_num_atoms, self.input_height, self.input_width])\n        print(\"###########################################################\", input_tensor_reshaped.get_shape)\n\n        input_tensor_reshaped.set_shape((None, 1, self.input_num_capsule * self.input_num_atoms, self.input_height, self.input_width))\n\n        conv = K.conv3d(input_tensor_reshaped, self.W, strides=(self.input_num_atoms, self.strides, self.strides), padding=self.padding, data_format='channels_first')\n        conv  = Lambda(lambda x : tf.nn.sigmoid(x) )(conv)       \n        \n        print(\"*******%%%%%%%%%%5\", conv.get_shape())\n        votes_shape = K.shape(conv)\n        _, _, _, conv_height, conv_width = conv.get_shape()\n        conv = tf.transpose(conv, [0, 2, 1, 3, 4])\n        votes = K.reshape(conv, [input_shape[0], self.input_num_capsule, self.num_capsule, self.num_atoms, votes_shape[3], votes_shape[4]])\n        print(\"*******%%%%%%%%%%5\", votes.get_shape())\n        votes.set_shape((None, self.input_num_capsule, self.num_capsule, self.num_atoms, conv_height.value, conv_width.value))\n        print(\"*******%%%%%%%%%%5\", votes.get_shape())\n\n        logit_shape = K.stack([input_shape[0], self.input_num_capsule, self.num_capsule, votes_shape[3], votes_shape[4]])\n        biases_replicated = K.tile(self.b, [1, 1, conv_height.value, conv_width.value])\n\n        activations = update_routing(\n            votes=votes,\n            biases=biases_replicated,\n            logit_shape=logit_shape,\n            num_dims=6,\n            input_dim=self.input_num_capsule,\n            output_dim=self.num_capsule,\n            num_routing=self.routings)\n\n        a2 = tf.transpose(activations, [0, 3, 4, 1, 2])\n        return a2\n\n    def compute_output_shape(self, input_shape):\n        space = input_shape[1:-2]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_output_length(space[i], self.kernel_size, padding=self.padding, stride=self.strides, dilation=1)\n            new_space.append(new_dim)\n\n        return (input_shape[0],) + tuple(new_space) + (self.num_capsule, self.num_atoms)\n\n    def get_config(self):\n        config = {\n            'kernel_size': self.kernel_size,\n            'num_capsule': self.num_capsule,\n            'num_atoms': self.num_atoms,\n            'strides': self.strides,\n            'padding': self.padding,\n            'routings': self.routings,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer)\n        }\n        base_config = super(ConvCapsuleLayer3, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T16:10:59.254711Z","iopub.execute_input":"2024-10-07T16:10:59.255118Z","iopub.status.idle":"2024-10-07T16:10:59.277081Z","shell.execute_reply.started":"2024-10-07T16:10:59.255080Z","shell.execute_reply":"2024-10-07T16:10:59.276093Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"# **Concatanate_mid class**","metadata":{}},{"cell_type":"code","source":"def _squash(input_tensor):\n    norm = tf.norm(input_tensor, axis=-1, keep_dims=True)\n    norm_squared = norm * norm\n    return (input_tensor / norm) * (norm_squared / (1 + norm_squared))\n\nclass Concatanate_mid(layers.Layer):\n    def __init__(self, **kwargs):\n        super(Concatanate_mid, self).__init__(**kwargs)\n#         self.b_initializer = initializers.get(constant_initializer)\n#         self.a_initializer = initializers.get(constant_initializer)\n\n    def build(self, input_shape):\n        # Transform matrix\n        self.A = self.add_weight(shape=[1],\n                                 initializer=initializers.constant(1),\n                                 name='A')\n#        self.B = self.add_weight(shape=[1],\n#                                 initializer=initializers.constant(1),\n#                                 name='B')\n        self.built = True\n\n    def call(self, inputs, training=None):\n        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n\n        inputs1 = inputs[0]\n        inputs2 = inputs[1]\n            \n        alpha = self.A\n#        beta = self.B\n        print(alpha)\n        output_cat =layers.Concatenate(axis=-2)([(1-alpha)*inputs1, alpha*inputs2])\n                      \n        return output_cat\n    \n    def compute_output_shape(self, input_shape):\n        input_shapes = input_shape\n        output_shape = list(input_shapes[0])\n        output_shape[1]=output_shape[1]+list(input_shapes[1])[1]\n        output_shape[0] = None\n        return tuple(output_shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T16:11:35.054417Z","iopub.execute_input":"2024-10-07T16:11:35.054815Z","iopub.status.idle":"2024-10-07T16:11:35.064807Z","shell.execute_reply.started":"2024-10-07T16:11:35.054777Z","shell.execute_reply":"2024-10-07T16:11:35.063889Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"# **update_routing class**","metadata":{}},{"cell_type":"code","source":"def _squash_d3(input_tensor):\n    in2 = tf.transpose(input_tensor, [0,1,3,4,2])\n    norm = tf.norm(in2, axis=-1, keep_dims=True)\n    norm_squared = norm * norm\n    x = (in2 / norm) * (norm_squared / (1 + norm_squared))\n    p = tf.transpose(x, [0,1,4,2,3])\n    return p\n\n\ndef update_routing(votes, biases, logit_shape, num_dims, input_dim, output_dim,\n                   num_routing):\n    if num_dims == 6:\n        votes_t_shape = [3, 0, 1, 2, 4, 5]\n        r_t_shape =     [1, 2, 3, 0, 4, 5]\n    elif num_dims == 4:\n        votes_t_shape = [3, 0, 1, 2]\n        r_t_shape = [1, 2, 3, 0]\n    else:\n        raise NotImplementedError('Not implemented')\n\n    votes_trans = tf.transpose(votes, votes_t_shape)\n    _, _, _, height, width, caps = votes_trans.get_shape()\n\n    def _body(i, logits, activations):\n        \"\"\"Routing while loop.\"\"\"\n        # route: [batch, input_dim, output_dim, ...]\n        route = tf.nn.softmax(logits, dim=2)\n        preactivate_unrolled = route * votes_trans\n        preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)\n        preactivate = tf.reduce_sum(preact_trans, axis=1) + biases\n        activation = _squash_d3(preactivate)\n        activations = activations.write(i, activation)\n\n        act_3d = K.expand_dims(activation, 1)\n        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n        tile_shape[1] = input_dim\n        act_replicated = tf.tile(act_3d, tile_shape)\n        distances = tf.reduce_sum(votes * act_replicated, axis=3)\n        logits += distances\n        return (i + 1, logits, activations)\n\n    activations = tf.TensorArray(\n        dtype=tf.float32, size=num_routing, clear_after_read=False)\n    logits = tf.fill(logit_shape, 0.0)\n\n    i = tf.constant(0, dtype=tf.int32)\n    _, logits, activations = tf.while_loop(\n        lambda i, logits, activations: i < num_routing,\n        _body,\n        loop_vars=[i, logits, activations],\n        swap_memory=True)\n    a = K.cast(activations.read(num_routing - 1), dtype='float32')\n    print(\"###########################################################\", a.get_shape)\n    return K.cast(activations.read(num_routing - 1), dtype='float32')\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T16:12:11.719068Z","iopub.execute_input":"2024-10-07T16:12:11.719846Z","iopub.status.idle":"2024-10-07T16:12:11.734939Z","shell.execute_reply.started":"2024-10-07T16:12:11.719806Z","shell.execute_reply":"2024-10-07T16:12:11.733966Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"# **Length**","metadata":{}},{"cell_type":"code","source":"class Length(layers.Layer):\n    \"\"\"\n    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n    inputs: shape=[None, num_vectors, dim_vector]\n    output: shape=[None, num_vectors]\n    \"\"\"\n    def call(self, inputs, **kwargs):\n        return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[:-1]\n\n    def get_config(self):\n        config = super(Length, self).get_config()\n        return config\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T17:12:04.510096Z","iopub.execute_input":"2024-10-07T17:12:04.510992Z","iopub.status.idle":"2024-10-07T17:12:04.517287Z","shell.execute_reply.started":"2024-10-07T17:12:04.510948Z","shell.execute_reply":"2024-10-07T17:12:04.516276Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"markdown","source":"# **CapsNet**","metadata":{}},{"cell_type":"code","source":"tf.keras.layers.Conv2DTranspose","metadata":{"execution":{"iopub.status.busy":"2024-10-07T17:25:26.986922Z","iopub.execute_input":"2024-10-07T17:25:26.987367Z","iopub.status.idle":"2024-10-07T17:25:26.994043Z","shell.execute_reply.started":"2024-10-07T17:25:26.987324Z","shell.execute_reply":"2024-10-07T17:25:26.992948Z"},"trusted":true},"execution_count":176,"outputs":[{"execution_count":176,"output_type":"execute_result","data":{"text/plain":"keras.src.layers.convolutional.conv2d_transpose.Conv2DTranspose"},"metadata":{}}]},{"cell_type":"code","source":"\ndef CapsNet(input_shape, n_class, routings,inst_parameter):\n    \"\"\"\n    A Capsule Network on MNIST.\n    :param input_shape: data shape, 3d, [width, height, channels]\n    :param n_class: number of classes\n    :param routings: number of routing iterations\n    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n            `eval_model` can also be used for training.\n    \"\"\"\n    x = layers.Input(shape=(360,1))\n    #x = layers.Input(shape=(784,1))\n    #x = layers.Input(input_shape)\n    \n    \n    l = layers.Conv1D(filters=64, kernel_size=7, strides=1, padding='same', activation='relu', name='conv1')(x)\n    l = layers.BatchNormalization()(l)\n    l = layers.Conv1D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu', name='conv2')(l)\n    l2= layers.Conv1D(filters=32, kernel_size=1, strides=1, padding='same', activation='relu', name='convl1')(l)\n    l2 = layers.BatchNormalization()(l2)\n    l2 = layers.Reshape((36,10,32))(l2)\n    #l2 = Lambda(lambda x: K.expand_dims(x,2))(l2)\n    l2 = Lambda(lambda x: K.expand_dims(x, 2), \n                output_shape=lambda s: (s[0], s[1], 1, s[2], s[3]))(l2)\n\n    #    l2 = Lambda(lambda x: tf.transpose(x,[0,3,2,1]))(l2)\n    #l2 = sqash_caps()(l2)\n    l2 = Lambda(lambda x: _squash_d3(x), \n                output_shape=lambda s: s)(l2)\n    l2 = ConvCapsuleLayer3(kernel_size=3, num_capsule=10, num_atoms=8, strides=1, padding='same', routings=3)(l2)\n    l2 = layers.BatchNormalization()(l2)\n    \n    \n    l1= layers.Conv1D(filters=32, kernel_size=1, strides=1, padding='same', activation='relu', name='convl1_1')(l)\n    l1 = layers.BatchNormalization()(l1)\n    l1 = layers.Reshape((36, 10, 32))(l1)\n    #l1 = Lambda(lambda x: K.expand_dims(x,2))(l)\n    l1 = Lambda(lambda x: K.expand_dims(x, 2), \n                output_shape=lambda s: (s[0], s[1], 1, s[2], s[3]))(l1)\n    #l1 = layers.Reshape((360,1,8,8))(l1)\n    #l1 = layers.Reshape((360,1,1,10))(l1)\n    #l1 = sqash_caps()(l1)\n    l1 = Lambda(lambda x: _squash(x), \n                output_shape=lambda s: s)(l1)\n    l1 = ConvCapsuleLayer3(kernel_size=3, num_capsule=8, num_atoms=8, strides=1, padding='same', routings=3)(l1)\n    l1 = layers.BatchNormalization()(l1)\n    \n    la = FlattenCaps()(l2)\n    lb = FlattenCaps()(l1)\n    \n#     lb = FlattenCaps()(l_skip)\n    \n    l = Concatanate_mid()([la, lb])\n    #print(l.get_shape())\n    print(l.shape)\n#    layers.Concatenate(axis=-2)([la, lb])\n    \n    #digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=inst_parameter, routings=routings,\n     #                        name='digitcaps')(l)\n    channels = l.shape[-1]  # This will take the last dimension of 'l' which is the number of channels\n    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=inst_parameter, routings=routings,\n                             channels=channels,  # Add the channels parameter here\n                             name='digitcaps')(l)\n    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n    # If using tensorflow, this will not be necessary. :)\n    out_caps = Length(name='capsnet')(digitcaps)\n\n    # Decoder network.\n    y = layers.Input(shape=(n_class,))\n    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n    # Shared Decoder model in training and prediction\n    decoder = models.Sequential(name='decoder')\n    #decoder.add(layers.Dense(56, activation='relu', input_dim=16*n_class))\n    #decoder.add(layers.GRU(512,dropout=0.1,recurrent_dropout=0.1))\n    #decoder.add(layers.Conv2DTranspose(filters=16*n_class,kernel_size=(10,1),\n     #                                        data_format=\"channels_last\"))\n    decoder.add(layers.Dense(256, activation='tanh',input_shape=(inst_parameter*n_class,)))\n    decoder.add(layers.Dense(45, activation='tanh'))\n    decoder.add(layers.Reshape((1,45,1)))\n    \n    \n\n        \n##################################################################\n    \n    decoder.add(layers.Conv2DTranspose(32,  kernel_size=(1, 3),strides=(1, 1),padding='same'))\n    decoder.add(layers.BatchNormalization())\n    decoder.add(layers.Conv2DTranspose(16, kernel_size=(1, 3),strides=(1, 2),padding='same'))\n    decoder.add(layers.BatchNormalization())\n    decoder.add(layers.Conv2DTranspose(8, kernel_size=(1, 5),strides=(1, 2),padding='same'))\n    decoder.add(layers.BatchNormalization())\n    decoder.add(layers.Conv2DTranspose(4, kernel_size=(1, 7),strides=(1, 2),padding='same'))\n    decoder.add(layers.BatchNormalization())\n    decoder.add(layers.Conv2DTranspose(1, kernel_size=(1, 7),strides=(1, 1),padding='same'))\n    decoder.add(layers.BatchNormalization())\n\n    #    decoder.add(Activation(\"tanh\"))\n    decoder.add(layers.Reshape((360,1)))\n#     decoder.add(layers.GRU(56,dropout=0.1,recurrent_dropout=0.1))\n#     decoder.add(Flatten())\n    print('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^')\n#     decoder.add(layers.Reshape(target_shape=(360,1), name='out_recon'))\n    \n    # Models for training and evaluation (prediction)\n    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n    eval_model = models.Model(x, [out_caps, decoder(masked)])\n    #print(\"SSSSSSSSSSSSSSSSS\",decoder.layers[-1].output_shape)\n    print(\"Decoder Output Shape:\", decoder.output_shape)\n\n    # manipulate model\n    noise = layers.Input(shape=(n_class, inst_parameter))\n    noised_digitcaps = layers.Add()([digitcaps, noise])\n    masked_noised_y = Mask()([noised_digitcaps, y])\n    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n    return train_model, eval_model, manipulate_model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T18:10:29.761542Z","iopub.execute_input":"2024-10-07T18:10:29.762072Z","iopub.status.idle":"2024-10-07T18:10:29.786779Z","shell.execute_reply.started":"2024-10-07T18:10:29.762035Z","shell.execute_reply":"2024-10-07T18:10:29.785778Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"\n\ndef margin_loss(y_true, y_pred):\n    \"\"\"\n    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n    :param y_true: [None, n_classes]\n    :param y_pred: [None, num_capsule]\n    :return: a scalar loss value.\n    \"\"\"\n    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n\n    return K.mean(K.sum(L, 1))\n\n\ndef train(model, data, args):\n    \"\"\"\n    Training a CapsuleNet\n    :param model: the CapsuleNet model\n    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n    :param args: arguments\n    :return: The trained model\n    \"\"\"\n    # unpacking the data\n    (x_train, y_train), (x_test, y_test) = data\n\n    # callbacks\n    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n#     tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs',\n#                                batch_size=args.batch_size, histogram_freq=int(args.debug))\n    #checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n     #                                       save_weights_only=True, verbose=1)\n    checkpoint = callbacks.ModelCheckpoint(\n    args.save_dir + '/weights-{epoch:02d}.weights.h5',  # Change this line\n    monitor='val_capsnet_acc',\n    save_weights_only=True,\n    verbose=1)\n\n    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n\n    # compile the model\n    model.compile(optimizer=optimizers.Adam(learning_rate=args.lr),\n                  loss=[margin_loss, 'mse'],\n                  loss_weights=[1., args.lam_recon],\n                  metrics={'capsnet': 'accuracy'})\n\n    # from sklearn.utils.class_weight import compute_class_weight\n    # class_weights=compute_class_weight('balanced',np.unique(np.argmax(y_train,axis=1)),np.argmax(y_train,axis=1))\n    # Training without data augmentation:\n    #model.fit([x_train[:,0:-1,:], y_train], [y_train, x_train[:,0:-1,:]], batch_size=args.batch_size, epochs=args.epochs,\n     #         validation_data=[[x_test[:,0:-1,:], y_test], [y_test, x_test[:,0:-1,:]]],callbacks=[log,checkpoint, lr_decay],shuffle=True)\n\n    x_train_reshaped = x_train.reshape(x_train.shape[0], -1, 1)\n    x_test_reshaped = x_test.reshape(x_test.shape[0], -1, 1)\n\n    model.fit([x_train_reshaped, y_train], [y_train, x_train_reshaped], \n              batch_size=args.batch_size, epochs=args.epochs,\n              validation_data=[[x_test_reshaped, y_test], [y_test, x_test_reshaped]],\n              callbacks=[log, checkpoint, lr_decay], shuffle=True)\n\n    #x_train = x_train.reshape(60000, 28*28, 1)  # (60000, 784, 1)\n    #x_test = x_test.reshape(10000, 28*28, 1)    # (10000, 784, 1)\n    #model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n     #         validation_data=[[x_test, y_test], [y_test, x_test]],callbacks=[log,checkpoint, lr_decay],shuffle=True)\n\n    #   ,class_weight=dict(enumerate(class_weights)))\n    \n\n    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n#     def train_generator(x, y, batch_size, shift_fraction=0.):\n#         train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n#                                            height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n#         generator = train_datagen.flow(x, y, batch_size=batch_size)\n#         while 1:\n#             x_batch, y_batch = generator.next()\n#             print(x_batch.shape, y_batch.shape)\n#             yield ([x_batch, y_batch], [y_batch, x_batch])\n\n#     # Training with data augmentation. If shift_fraction=0., also no augmentation.\n#     model.fit_generator(generator=train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n#                         steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n#                         epochs=args.epochs,\n#                         validation_data=[[x_test, y_test], [y_test, x_test]])\n    # End: Training with data augmentation -----------------------------------------------------------------------#\n\n    model.save_weights(args.save_dir + '/trained_model.h5')\n    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n\n#     from utils import plot_log\n#     plot_log(args.save_dir + '/log.csv', show=True)\n\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T18:12:03.503479Z","iopub.execute_input":"2024-10-07T18:12:03.503884Z","iopub.status.idle":"2024-10-07T18:12:03.517018Z","shell.execute_reply.started":"2024-10-07T18:12:03.503846Z","shell.execute_reply":"2024-10-07T18:12:03.516013Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"# **Testing**","metadata":{}},{"cell_type":"code","source":"\ndef test(model, data, args):\n    x_test, y_test = data\n    y_pred, x_recon = model.predict(x_test[:,0:-1,:], batch_size=100)\n    print('-'*30 + 'Begin: test' + '-'*30)\n    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n    print('#####################recon shape')\n    #mage = combine_images_1d(x_test[:50],x_recon[:50],args.save_dir)\n    num = 500\n    plt.figure(figsize=(8,500))\n    for i in range(1, num+1):\n        plt.subplot(num,2, i)\n        if (i%2==1):\n            plt.plot(x_test[i//2,:,:])\n        else:\n            plt.plot(x_recon[i//2,:,:])\n    plt.savefig(args.save_dir + \"/real_and_recon.png\")\n    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n    print('-' * 30 + 'End: test' + '-' * 30)\n    from sklearn.metrics import confusion_matrix\n    cm=confusion_matrix(np.argmax(y_pred,axis=1),np.argmax(y_test,axis=1))\n    print(cm)\n    \n#     plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n#     plt.show()\n\n\ndef manipulate_latent(model, data, args):\n    print('-'*30 + 'Begin: manipulate' + '-'*30)\n    x_test, y_test = data\n    index = np.argmax(y_test, 1) == args.digit\n    number = np.random.randint(low=0, high=sum(index) - 1)\n    x, y = x_test[index][number], y_test[index][number]\n    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n    noise = np.zeros([1, 10, 16])\n    x_recons = []\n    for dim in range(16):\n        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n            tmp = np.copy(noise)\n            tmp[:,:,dim] = r\n            x_recon = model.predict([x, y, tmp])\n            x_recons.append(x_recon)\n\n    x_recons = np.concatenate(x_recons)\n\n    img = combine_images(x_recons, height=16)\n    image = img*255\n    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n    print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n    print('-' * 30 + 'End: manipulate' + '-' * 30)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T18:12:05.723928Z","iopub.execute_input":"2024-10-07T18:12:05.724920Z","iopub.status.idle":"2024-10-07T18:12:05.744661Z","shell.execute_reply.started":"2024-10-07T18:12:05.724867Z","shell.execute_reply":"2024-10-07T18:12:05.743655Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"markdown","source":"# **Data and Main Function**","metadata":{}},{"cell_type":"code","source":"\ndef load_mnist():\n    # the data, shuffled and split between train and test sets\n    x_train=[]\n    x_test=[]\n    ind=0\n    train_label=[]\n    test_label=[]\n    from keras.datasets import mnist\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n    y_train = to_categorical(y_train.astype('float32'))\n    y_test = to_categorical(y_test.astype('float32'))\n    return (x_train, y_train), (x_test, y_test)\n    print(x_train.shape)\n    print(x_test.shape)\n    return (x_train, y_train), (x_test, y_test)\n\n\nimport sys\nimport argparse\n\nimport sys\nimport argparse\n\ndef load_mnist():\n    # load mnist dataset\n    from keras.datasets import mnist\n    from keras.utils import to_categorical\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n    y_train = to_categorical(y_train.astype('float32'))\n    y_test = to_categorical(y_test.astype('float32'))\n    return (x_train, y_train), (x_test, y_test)\n\nif __name__ == \"__main__\":\n    # setting the hyper parameters\n    parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n    parser.add_argument('--epochs', default=25, type=int)\n    parser.add_argument('--batch_size', default=50, type=int)\n    parser.add_argument('--inst_parameter', default=8, type=int)\n    parser.add_argument('--lr', default=0.001, type=float, help=\"Initial learning rate\")\n    parser.add_argument('--lr_decay', default=0.9, type=float, help=\"The value multiplied by lr at each epoch\")\n    parser.add_argument('--lam_recon', default=0.392, type=float, help=\"The coefficient for the loss of decoder\")\n    parser.add_argument('-r', '--routings', default=3, type=int, help=\"Number of iterations used in routing algorithm\")\n    parser.add_argument('--shift_fraction', default=0.1, type=float, help=\"Fraction of pixels to shift at most in each direction.\")\n    parser.add_argument('--debug', action='store_true', help=\"Save weights by TensorBoard\")\n    parser.add_argument('--save_dir', default='./after_notations_more_classes_changed_decoder_alpha_8')\n    parser.add_argument('-t', '--testing', action='store_true', help=\"Test the trained model on testing dataset\")\n    parser.add_argument('--digit', default=5, type=int, help=\"Digit to manipulate\")\n    parser.add_argument('-w', '--weights', default=None, help=\"The path of the saved weights. Should be specified when testing\")\n    \n    # Filter out Jupyter's own arguments\n    args = parser.parse_args([arg for arg in sys.argv if arg.startswith(\"--\")])\n    print(args)\n\n    # Check if save directory exists, create if it doesn't\n    import os\n    if not os.path.exists(args.save_dir):\n        os.makedirs(args.save_dir)\n    \n    # Load data\n    (x_train, y_train), (x_test, y_test) = load_mnist()\n    print(x_train.shape, y_train.shape)\n    \n    # Define and initialize model (assuming the CapsNet function is defined elsewhere)\n    model, eval_model, manipulate_model = CapsNet(input_shape=(360,1), n_class=y_train.shape[1], routings=args.routings, inst_parameter=args.inst_parameter)\n    model.summary()\n    \n    # Train or test the model\n    train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)\n    test(model=eval_model, data=(x_test, y_test), args=args)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T18:12:09.357280Z","iopub.execute_input":"2024-10-07T18:12:09.357675Z","iopub.status.idle":"2024-10-07T18:12:11.075027Z","shell.execute_reply.started":"2024-10-07T18:12:09.357637Z","shell.execute_reply":"2024-10-07T18:12:11.073743Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stdout","text":"Namespace(epochs=25, batch_size=50, inst_parameter=8, lr=0.001, lr_decay=0.9, lam_recon=0.392, routings=3, shift_fraction=0.1, debug=False, save_dir='./after_notations_more_classes_changed_decoder_alpha_8', testing=False, digit=5, weights=None)\n(60000, 28, 28, 1) (60000, 10)\n(None, 648, 8)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nDecoder Output Shape: (None, 360, 1)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_223\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_223\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_74      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1 (\u001b[38;5;33mConv1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ input_layer_74[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2 (\u001b[38;5;33mConv1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ convl1 (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m2,080\u001b[0m │ conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ convl1_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m2,080\u001b[0m │ conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ convl1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ convl1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_81          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_82          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_99 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ reshape_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_101 (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ reshape_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_100 (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ lambda_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_102 (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ lambda_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv_capsule_layer… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, │      \u001b[38;5;34m7,760\u001b[0m │ lambda_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mConvCapsuleLayer3\u001b[0m) │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv_capsule_layer… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m,  │      \u001b[38;5;34m6,208\u001b[0m │ lambda_102[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mConvCapsuleLayer3\u001b[0m) │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, │         \u001b[38;5;34m32\u001b[0m │ conv_capsule_lay… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m,  │         \u001b[38;5;34m32\u001b[0m │ conv_capsule_lay… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_caps_38     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mFlattenCaps\u001b[0m)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_caps_39     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mFlattenCaps\u001b[0m)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatanate_mid_19  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m648\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │          \u001b[38;5;34m1\u001b[0m │ flatten_caps_38[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatanate_mid\u001b[0m)   │                   │            │ flatten_caps_39[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ digitcaps           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │      \u001b[38;5;34m5,200\u001b[0m │ concatanate_mid_… │\n│ (\u001b[38;5;33mCapsuleLayer\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_75      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ mask_38 (\u001b[38;5;33mMask\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ digitcaps[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ input_layer_75[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ capsnet (\u001b[38;5;33mLength\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ digitcaps[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │     \u001b[38;5;34m35,130\u001b[0m │ mask_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_74      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ convl1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ convl1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ convl1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ convl1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_81          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_82          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv_capsule_layer… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,760</span> │ lambda_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvCapsuleLayer3</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv_capsule_layer… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ lambda_102[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvCapsuleLayer3</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ conv_capsule_lay… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ conv_capsule_lay… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_caps_38     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FlattenCaps</span>)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_caps_39     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FlattenCaps</span>)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatanate_mid_19  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">648</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │ flatten_caps_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatanate_mid</span>)   │                   │            │ flatten_caps_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ digitcaps           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,200</span> │ concatanate_mid_… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_75      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ mask_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Mask</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ digitcaps[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ input_layer_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ capsnet (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Length</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ digitcaps[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">35,130</span> │ mask_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,091\u001b[0m (312.86 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,091</span> (312.86 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,681\u001b[0m (311.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,681</span> (311.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m410\u001b[0m (1.60 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410</span> (1.60 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[243], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Train or test the model\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m test(model\u001b[38;5;241m=\u001b[39meval_model, data\u001b[38;5;241m=\u001b[39m(x_test, y_test), args\u001b[38;5;241m=\u001b[39margs)\n","Cell \u001b[0;32mIn[241], line 54\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, args)\u001b[0m\n\u001b[1;32m     51\u001b[0m     x_train_reshaped \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mreshape(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m     x_test_reshaped \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mreshape(x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_reshaped\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_reshaped\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m#x_train = x_train.reshape(60000, 28*28, 1)  # (60000, 784, 1)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m#x_test = x_test.reshape(10000, 28*28, 1)    # (10000, 784, 1)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m#model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#                         validation_data=[[x_test, y_test], [y_test, x_test]])\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# End: Training with data augmentation -----------------------------------------------------------------------#\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_weights(args\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/trained_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_223\" is incompatible with the layer: expected shape=(None, 360, 1), found shape=(50, 784)"],"ename":"ValueError","evalue":"Input 0 of layer \"functional_223\" is incompatible with the layer: expected shape=(None, 360, 1), found shape=(50, 784)","output_type":"error"}]},{"cell_type":"code","source":"print(\"x_train shape:\", x_train.shape)\nprint(\"x_test shape:\", x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T17:55:00.885310Z","iopub.execute_input":"2024-10-07T17:55:00.886300Z","iopub.status.idle":"2024-10-07T17:55:00.892180Z","shell.execute_reply.started":"2024-10-07T17:55:00.886248Z","shell.execute_reply":"2024-10-07T17:55:00.891087Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"x_train shape: (60000, 28, 28, 1)\nx_test shape: (10000, 28, 28, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef load_mnist():\n    # the data, shuffled and split between train and test sets\n    x_train=[]\n    x_test=[]\n    ind=0\n    train_label=[]\n    test_label=[]\n    folder=os.listdir('./train_96_low_classes')\n    print(folder)\n    for fl in folder:\n        file_name=os.listdir('./train_96_low_classes'+'/'+fl)\n        for i in file_name:\n            try:\n                train_image = np.load('./train_96_low_classes'+'/'+fl+'/'+i,allow_pickle=True)\n            except:\n                pass\n            temp = train_image-np.mean(train_image)\n            x_train.append(temp/np.max(np.abs(temp)))\n        len_train=len(file_name)     \n        train_label.extend([ind]*len_train)\n        ind=ind+1\n    x_train=np.array(x_train)\n    folder=os.listdir('./test_96_low_classes')\n    ind=0\n    for fl in folder:\n        file_name=os.listdir('./test_96_low_classes'+'/'+fl)\n        for i in file_name:\n            try:\n                test_image = np.load('./test_96_low_classes'+'/'+fl+'/'+i,allow_pickle=True)\n            except:\n                pass\n            \n            temp = test_image-np.mean(test_image)\n            x_test.append(temp/np.max(np.abs(temp)))\n        len_test=len(file_name)     \n        test_label.extend([ind]*len_test)\n        ind=ind+1                     \n    x_test=np.array(x_test)\n    x_train = x_train.reshape(-1, 361, 1).astype('float32')\n    x_test = x_test.reshape(-1, 361, 1).astype('float32')\n    y_train = to_categorical(np.array(train_label).astype('float32'))\n    y_test = to_categorical(np.array(test_label).astype('float32'))\n    print(x_train.shape)\n    print(x_test.shape)\n    return (x_train, y_train), (x_test, y_test)\n\n\nif __name__ == \"__main__\":\n    import os\n    import argparse\n    #from keras.preprocessing.image import ImageDataGenerator\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    from keras import callbacks\n\n    # setting the hyper parameters\n    parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n    parser.add_argument('--epochs', default=25, type=int)\n    parser.add_argument('--batch_size', default=50, type=int)\n    parser.add_argument('--inst_parameter', default=8, type=int)\n    parser.add_argument('--lr', default=0.001, type=float,\n                        help=\"Initial learning rate\")\n    parser.add_argument('--lr_decay', default=0.9, type=float,\n                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n    parser.add_argument('--lam_recon', default=0.392, type=float,\n                        help=\"The coefficient for the loss of decoder\")\n    parser.add_argument('-r', '--routings', default=3, type=int,\n                        help=\"Number of iterations used in routing algorithm. should > 0\")\n    parser.add_argument('--shift_fraction', default=0.1, type=float,\n                        help=\"Fraction of pixels to shift at most in each direction.\")\n    parser.add_argument('--debug', action='store_true',\n                        help=\"Save weights by TensorBoard\")\n    parser.add_argument('--save_dir', default='./after_notations_more_classes_changed_decoder_alpha_8')\n    parser.add_argument('-t', '--testing', action='store_true',\n                        help=\"Test the trained model on testing dataset\")\n    parser.add_argument('--digit', default=5, type=int,\n                        help=\"Digit to manipulate\")\n    parser.add_argument('-w', '--weights', default=None,\n                        help=\"The path of the saved weights. Should be specified when testing\")\n    args = parser.parse_args()\n    print(args)\n\n    if not os.path.exists(args.save_dir):\n        os.makedirs(args.save_dir) \n\n    # load data\n    (x_train, y_train), (x_test, y_test) = load_mnist()\n    print(x_train.shape, y_train.shape)\n    # define model\n    model, eval_model, manipulate_model = CapsNet(input_shape=(360,1),\n                                                  n_class=y_train.shape[1],\n                                                  routings=args.routings,\n                                                 inst_parameter=args.inst_parameter)\n    model.summary()\n\n    # train or test\n#     if args.weights is not None:  # init the model weights with provided one\n#         model.load_weights(args.weights)\n#     if not args.testing:\n    train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)\n#     else:  # as long as weights are given, will run testing\n#         if args.weights is None:\n#             print('No weights are provided. Will test using random initialized weights.')\n#         manipulate_latent(manipulate_model, (x_test, y_test), args)\n#    maximum_weights=os.listdir(args.save_dir)\n#    model.load_weights(args.save_dir+'\\\\'+maximum_weights[-3])\n    \n    test(model=eval_model, data=(x_test, y_test), args=args)","metadata":{},"execution_count":null,"outputs":[]}]}